{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from skimage import color\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "from skimage import morphology\n",
    "import scipy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_len = 28\n",
    "image_wid = 28\n",
    "n_augmentation = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "def rescale_down_sample(img, new_len, new_wid):\n",
    "    img = resize(img, (new_len, new_wid))\n",
    "    assert img.shape == (new_len,new_wid), \"Image is \" + str(img.shape)\n",
    "    return img\n",
    "\n",
    "def rotate_image(img, theta):\n",
    "    pil_img = Image.fromarray(np.uint8((1-img)*255), \"L\")\n",
    "    rotated_img = pil_img.rotate(theta)\n",
    "    return (255 - np.array(rotated_img))/255.\n",
    "\n",
    "def unzoom_image(img, unzoom):\n",
    "    assert unzoom <= 1,\"unzoom must be <= 1\"\n",
    "    length, width = img.shape\n",
    "    pad_len_inf = math.floor((28/unzoom-length)/2)\n",
    "    pad_len_sup = math.ceil((28/unzoom-length)/2)\n",
    "    pad_wid_inf = math.floor((28/unzoom-width)/2)\n",
    "    pad_wid_sup = math.ceil((28/unzoom-width)/2)\n",
    "    padded_img = np.pad(img, ((pad_len_inf, pad_len_sup),(pad_wid_inf, pad_wid_sup)), constant_values = 1)\n",
    "    return scipy.ndimage.zoom(padded_img, unzoom, cval=1)\n",
    "\n",
    "def translate(img, dx, dy):\n",
    "    length, width = img.shape\n",
    "    while min(list(set(img[:, width - abs(dx):].flatten()))) < 0.98:\n",
    "        dx -=1\n",
    "        if dx == 1:\n",
    "            break\n",
    "    while min(list(set(img[length-abs(dy):, :].flatten()))) <0.98:\n",
    "        dy -=1\n",
    "        if dy == 1:\n",
    "            break\n",
    "    x_moved = np.roll(img, dx, 1)\n",
    "    return np.roll(x_moved, dy, 0)\n",
    "\n",
    "def apply_all(img, theta, unzoom, dx, dy):\n",
    "    return resize(translate(unzoom_image(rotate_image(img, theta),unzoom),dx,dy), (28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(path = \"operators/\", image_len = 28, image_wid = 28, n_augmentation = 50):\n",
    "    \"\"\"\n",
    "    path : Root path to images folder\n",
    "    image_len, image_wid:  parameters of the out images\n",
    "    n_augmentation: number os generated samples for each images\n",
    "\n",
    "    output: a dictionary with contains as key the signs, each key has a list of narrays.\n",
    "    \"\"\"\n",
    "    plus_image = color.rgb2gray(imageio.imread(path + \"+.png\"))\n",
    "    minus_image = color.rgb2gray(imageio.imread(path + \"-.png\"))\n",
    "    multiply_image = color.rgb2gray(imageio.imread(path + \"*.png\"))\n",
    "    divide_image = color.rgb2gray(imageio.imread(path + \"%.png\"))\n",
    "    equal_image = color.rgb2gray(imageio.imread(path + \"=.png\"))\n",
    "\n",
    "    plus_image_ds = rescale_down_sample(plus_image, image_len, image_wid)\n",
    "    minus_image_ds = rescale_down_sample(minus_image, image_len, image_wid)\n",
    "    multiply_image_ds = rescale_down_sample(multiply_image, image_len, image_wid)\n",
    "    divide_image_ds = rescale_down_sample(divide_image, image_len, image_wid)\n",
    "    equal_image_ds = rescale_down_sample(equal_image, image_len, image_wid)\n",
    "\n",
    "\n",
    "    augmented_data_set = {'+':[],'-':[],'*':[],'/':[],'=':[]}\n",
    "    for i in range(n_augmentation):\n",
    "        theta = random.randint(0,360) if random.uniform(0,1) > 0.2 else 0\n",
    "        unzoom = random.uniform(0.5, 1) if random.uniform(0,1) > 0.2 else 1\n",
    "        dx = random.randint(1, 5) if random.uniform(0,1) > 0.2 else 1\n",
    "        dy = random.randint(1, 5) if random.uniform(0,1) > 0.2 else 1\n",
    "        augmented_plus = apply_all(plus_image_ds,theta, unzoom, dx, dy)\n",
    "        augmented_minus = apply_all(minus_image_ds,theta, unzoom, dx, dy)\n",
    "        augmented_multiply = apply_all(multiply_image_ds,theta, unzoom, dx, dy)\n",
    "        augmented_divide = apply_all(divide_image_ds,theta, unzoom, dx, dy)\n",
    "        augmented_equal = apply_all(equal_image_ds,theta, unzoom, dx, dy)\n",
    "        augmented_data_set['+'].append(augmented_plus)\n",
    "        augmented_data_set['-'].append(augmented_minus)\n",
    "        augmented_data_set['*'].append(augmented_multiply)\n",
    "        augmented_data_set['/'].append(augmented_divide)\n",
    "        augmented_data_set['='].append(augmented_equal)\n",
    "\n",
    "    return augmented_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_operators = generate_data(path = \"operators/\", image_len = 28, image_wid = 28, n_augmentation = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_labeled(data):\n",
    "    data_labeled = np.zeros((len(data['+'])*5, 28, 28))\n",
    "    labels = np.zeros((len(data['+'])*5))\n",
    "    classes = {'+':10, '-': 11, '*':12, '/':13, '=':14}\n",
    "    \n",
    "    shift = 0\n",
    "    for i in data.keys():\n",
    "        for k in range(len(data[i])):\n",
    "            data_labeled[k+shift] = data[i][k]\n",
    "            labels[k+shift] = classes[i]\n",
    "        #We need a shift in order to avoid overwritting samples, each new key we start at zero    \n",
    "        shift += 100\n",
    "    return data_labeled, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_oper, labels_oper = data_labeled(data_operators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_oper shape:  (10000, 28, 28)\n",
      "labels_oper shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"data_oper shape: \", data_oper.shape)\n",
    "print(\"labels_oper shape: \", labels_oper.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_oper, labels_oper, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (8000, 28, 28)\n",
      "y_train shape:  (8000,)\n",
      "X_test shape:  (2000, 28, 28)\n",
      "y_test shape:  (2000,)\n"
     ]
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def extract_data(filename, image_shape, image_number):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(np.prod(image_shape) * image_number)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = data.reshape(image_number, image_shape[0], image_shape[1])\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_labels(filename, image_number):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * image_number)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (28, 28)\n",
    "train_set_size = 60000\n",
    "test_set_size = 10000\n",
    "\n",
    "data_part2_folder = os.path.join(\"/Users/user/Desktop/UPMC/EPFL/PatternRecognition/iapr-2020-master/data/lab-03-data\", 'part2')\n",
    "\n",
    "train_images_path = os.path.join(data_part2_folder, 'train-images-idx3-ubyte.gz')\n",
    "train_labels_path = os.path.join(data_part2_folder, 'train-labels-idx1-ubyte.gz')\n",
    "test_images_path = os.path.join(data_part2_folder, 't10k-images-idx3-ubyte.gz')\n",
    "test_labels_path = os.path.join(data_part2_folder, 't10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "train_images = extract_data(train_images_path, image_shape, train_set_size)\n",
    "test_images = extract_data(test_images_path, image_shape, test_set_size)\n",
    "train_labels = extract_labels(train_labels_path, train_set_size)\n",
    "test_labels = extract_labels(test_labels_path, test_set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28), (60000,), (10000,))"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape, test_images.shape, train_labels.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = np.concatenate((train_images, X_train), axis=0)\n",
    "train_labels = np.concatenate((train_labels, y_train), axis=0)\n",
    "\n",
    "test_imgs = np.concatenate((test_images, X_test), axis=0)\n",
    "test_labels =  np.concatenate((test_labels, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape:  (68000, 28, 28)\n",
      "Train labels shape:  (68000,)\n",
      "Test images shape:  (12000, 28, 28)\n",
      "Test labels shape:  (12000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train images shape: \", train_imgs.shape)\n",
    "print(\"Train labels shape: \", train_labels.shape)\n",
    "print(\"Test images shape: \", test_imgs.shape)\n",
    "print(\"Test labels shape: \", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in train_labels:\n",
    "    if i not in labels:\n",
    "        labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels are:  [5.0, 0.0, 4.0, 1.0, 9.0, 2.0, 3.0, 6.0, 7.0, 8.0, 14.0, 11.0, 12.0, 10.0, 13.0]\n",
      "Number of labels:  15\n"
     ]
    }
   ],
   "source": [
    "print(\"Class labels are: \", labels)\n",
    "print(\"Number of labels: \", len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_images_norm = scaler.fit_transform(train_imgs.reshape(-1, 28*28)).reshape(-1, 28, 28)\n",
    "test_images_norm = scaler.transform(test_imgs.reshape(-1, 28*28)).reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 15)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def train_(self, n_epochs, learning_rate, batch_size):\n",
    "        self.train()\n",
    "        opt = optim.SGD(self.parameters(), lr=learning_rate)\n",
    "        losses = []\n",
    "        for n in range(n_epochs):\n",
    "            sum_loss = 0\n",
    "            for b in range(0, len(train_images_norm), batch_size):\n",
    "                predictions = self(torch.Tensor(train_images_norm).narrow(0, b, batch_size).view(-1, 1, 28, 28))\n",
    "                loss = F.nll_loss(predictions, torch.LongTensor(train_labels).narrow(0, b, batch_size))\n",
    "                sum_loss = sum_loss + loss.item()\n",
    "                self.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "            losses.append(sum_loss)\n",
    "        return losses\n",
    "            \n",
    "    def test_(self, batch_size):\n",
    "        nb_errors = 0\n",
    "        for b in range(0, len(test_images_norm), batch_size):\n",
    "            predictions = self(torch.Tensor(test_images_norm).view(-1, 1, 28, 28).narrow(0, b, batch_size))\n",
    "            predictions_classes = torch.argmax(predictions, dim = 1)\n",
    "            for k in range(batch_size):\n",
    "                if torch.Tensor(test_labels)[b+k].item() != predictions_classes[k].item():\n",
    "                    nb_errors += 1\n",
    "        return 1 - nb_errors*1.0/len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for CNN on test set with 10 epochs averaged over 5 runs : 0.79402\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "for iter_ in range(5):\n",
    "    cnn = CNN()\n",
    "    train_losses = cnn.train_(10, 0.2, 100)\n",
    "    accuracy = cnn.test_(100)\n",
    "    accuracies.append(accuracy)\n",
    "mean_accuracy = sum(accuracies)/5.0\n",
    "print(\"Accuracy for CNN on test set with 10 epochs averaged over 5 runs : \" + str(mean_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn.state_dict(), \"cnn1_weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.load_state_dict(torch.load(\"cnn1_weight\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
