{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from skimage import color\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "from skimage import morphology\n",
    "import scipy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_len = 28\n",
    "image_wid = 28\n",
    "n_augmentation = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "def rescale_down_sample(img, new_len, new_wid):\n",
    "    img = resize(img, (new_len, new_wid))\n",
    "    assert img.shape == (new_len,new_wid), \"Image is \" + str(img.shape)\n",
    "    return img\n",
    "\n",
    "def rotate_image(img, theta):\n",
    "    pil_img = Image.fromarray(np.uint8((1-img)*255), \"L\")\n",
    "    rotated_img = pil_img.rotate(theta)\n",
    "    return (255 - np.array(rotated_img))/255.\n",
    "\n",
    "def unzoom_image(img, unzoom):\n",
    "    assert unzoom <= 1,\"unzoom must be <= 1\"\n",
    "    length, width = img.shape\n",
    "    pad_len_inf = math.floor((28/unzoom-length)/2)\n",
    "    pad_len_sup = math.ceil((28/unzoom-length)/2)\n",
    "    pad_wid_inf = math.floor((28/unzoom-width)/2)\n",
    "    pad_wid_sup = math.ceil((28/unzoom-width)/2)\n",
    "    padded_img = np.pad(img, ((pad_len_inf, pad_len_sup),(pad_wid_inf, pad_wid_sup)), constant_values = 1)\n",
    "    return scipy.ndimage.zoom(padded_img, unzoom, cval=1)\n",
    "\n",
    "def translate(img, dx, dy):\n",
    "    length, width = img.shape\n",
    "    while min(list(set(img[:, width - abs(dx):].flatten()))) < 0.98:\n",
    "        dx -=1\n",
    "        if dx == 1:\n",
    "            break\n",
    "    while min(list(set(img[length-abs(dy):, :].flatten()))) <0.98:\n",
    "        dy -=1\n",
    "        if dy == 1:\n",
    "            break\n",
    "    x_moved = np.roll(img, dx, 1)\n",
    "    return np.roll(x_moved, dy, 0)\n",
    "\n",
    "def apply_all(img, theta, unzoom, dx, dy):\n",
    "    return resize(translate(unzoom_image(rotate_image(img, theta),unzoom),dx,dy), (28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"operators/\"\n",
    "\n",
    "plus_image = color.rgb2gray(imageio.imread(path + \"+.png\"))\n",
    "minus_image = color.rgb2gray(imageio.imread(path + \"-.png\"))\n",
    "multiply_image = color.rgb2gray(imageio.imread(path + \"*.png\"))\n",
    "divide_image = color.rgb2gray(imageio.imread(path + \"%.png\"))\n",
    "equal_image = color.rgb2gray(imageio.imread(path + \"=.png\"))\n",
    "\n",
    "plus_image_ds = rescale_down_sample(plus_image, image_len, image_wid)\n",
    "minus_image_ds = rescale_down_sample(minus_image, image_len, image_wid)\n",
    "multiply_image_ds = rescale_down_sample(multiply_image, image_len, image_wid)\n",
    "divide_image_ds = rescale_down_sample(divide_image, image_len, image_wid)\n",
    "equal_image_ds = rescale_down_sample(equal_image, image_len, image_wid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(path = \"operators/\", image_len = 28, image_wid = 28, n_augmentation = 50):\n",
    "    \"\"\"\n",
    "    path : Root path to images folder\n",
    "    image_len, image_wid:  parameters of the out images\n",
    "    n_augmentation: number os generated samples for each images\n",
    "\n",
    "    output: a dictionary with contains as key the signs, each key has a list of narrays.\n",
    "    \"\"\"\n",
    "    plus_image = color.rgb2gray(imageio.imread(path + \"+.png\"))\n",
    "    minus_image = color.rgb2gray(imageio.imread(path + \"-.png\"))\n",
    "    multiply_image = color.rgb2gray(imageio.imread(path + \"*.png\"))\n",
    "    divide_image = color.rgb2gray(imageio.imread(path + \"%.png\"))\n",
    "    equal_image = color.rgb2gray(imageio.imread(path + \"=.png\"))\n",
    "\n",
    "    plus_image_ds = rescale_down_sample(plus_image, image_len, image_wid)\n",
    "    minus_image_ds = rescale_down_sample(minus_image, image_len, image_wid)\n",
    "    multiply_image_ds = rescale_down_sample(multiply_image, image_len, image_wid)\n",
    "    divide_image_ds = rescale_down_sample(divide_image, image_len, image_wid)\n",
    "    equal_image_ds = rescale_down_sample(equal_image, image_len, image_wid)\n",
    "\n",
    "\n",
    "    augmented_data_set = {'+':[],'-':[],'*':[],'/':[],'=':[]}\n",
    "    for i in range(n_augmentation):\n",
    "        theta = random.randint(0,360) if random.uniform(0,1) > 0.2 else 0\n",
    "        unzoom = random.uniform(0.5, 1) if random.uniform(0,1) > 0.2 else 1\n",
    "        dx = random.randint(1, 5) if random.uniform(0,1) > 0.2 else 1\n",
    "        dy = random.randint(1, 5) if random.uniform(0,1) > 0.2 else 1\n",
    "        augmented_plus = apply_all(plus_image_ds,theta, unzoom, dx, dy)\n",
    "        augmented_minus = apply_all(minus_image_ds,theta, unzoom, dx, dy)\n",
    "        augmented_multiply = apply_all(multiply_image_ds,theta, unzoom, dx, dy)\n",
    "        augmented_divide = apply_all(divide_image_ds,theta, unzoom, dx, dy)\n",
    "        augmented_equal = apply_all(equal_image_ds,theta, unzoom, dx, dy)\n",
    "        augmented_data_set['+'].append(augmented_plus)\n",
    "        augmented_data_set['-'].append(augmented_minus)\n",
    "        augmented_data_set['*'].append(augmented_multiply)\n",
    "        augmented_data_set['/'].append(augmented_divide)\n",
    "        augmented_data_set['='].append(augmented_equal)\n",
    "\n",
    "    return augmented_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dic = {'+':0, '-': 1, '*':2, '/':3, '=':4}\n",
    "data = generate_data(path = \"operators/\", image_len = 28, image_wid = 28, n_augmentation = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus_image_ds = resize(plus_image, (image_len, image_wid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plus_image_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_labeled(data):\n",
    "    data_labeled = np.zeros((len(data['+'])*5, 28, 28))\n",
    "    labels = np.zeros((len(data['+'])*5, 1))\n",
    "    classes = {'+':0, '-': 1, '*':2, '/':3, '=':4}\n",
    "    \n",
    "    for i in data.keys():\n",
    "        shift = 0\n",
    "        for k in range(len(data[i])):\n",
    "            data_labeled[k+shift] = data[i][k]\n",
    "            labels[k+shift] = classes[i]\n",
    "        #We need a shift in order to avoid overwritting samples, each new key we start at zero    \n",
    "        shift += 100\n",
    "    return data_labeled, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (27,27) into shape (28,28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-cd35ed415013>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_labeled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-27a03697a610>\u001b[0m in \u001b[0;36mdata_labeled\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mshift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mdata_labeled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#We need a shift in order to avoid overwritting samples, each new key we start at zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (27,27) into shape (28,28)"
     ]
    }
   ],
   "source": [
    "X, Y = data_labeled(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28), (28, 28), (28, 28), (28, 28), (28, 28))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['+'][0].shape,  data['+'][1].shape, data['+'][2].shape, data['+'][1].shape, data['+'][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28), (28, 28)]\n"
     ]
    }
   ],
   "source": [
    "check_size = []\n",
    "for ele in data['-']:\n",
    "    check_size.append(ele.shape)\n",
    "print(check_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labeled = np.zeros((len(data['+'])*5, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['+'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6847aaac0b98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_images_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_images_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_images_norm = scaler.fit_transform(train_images.reshape(-1, 28*28)).reshape(-1, 28, 28)\n",
    "test_images_norm = scaler.transform(test_images.reshape(-1, 28*28)).reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def train_(self, n_epochs, learning_rate, batch_size):\n",
    "        self.train()\n",
    "        opt = optim.SGD(self.parameters(), lr=learning_rate)\n",
    "        losses = []\n",
    "        for n in range(n_epochs):\n",
    "            sum_loss = 0\n",
    "            for b in range(0, len(train_images_norm), batch_size):\n",
    "                predictions = self(torch.Tensor(train_images_norm).narrow(0, b, batch_size).view(-1, 1, 28, 28))\n",
    "                loss = F.nll_loss(predictions, torch.LongTensor(train_labels).narrow(0, b, batch_size))\n",
    "                sum_loss = sum_loss + loss.item()\n",
    "                self.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "            losses.append(sum_loss)\n",
    "        return losses\n",
    "            \n",
    "    def test_(self, batch_size):\n",
    "        nb_errors = 0\n",
    "        for b in range(0, len(test_images_norm), batch_size):\n",
    "            predictions = self(torch.Tensor(test_images_norm).view(-1, 1, 28, 28).narrow(0, b, batch_size))\n",
    "            predictions_classes = torch.argmax(predictions, dim = 1)\n",
    "            for k in range(batch_size):\n",
    "                if torch.Tensor(test_labels)[b+k].item() != predictions_classes[k].item():\n",
    "                    nb_errors += 1\n",
    "        return 1 - nb_errors*1.0/len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
